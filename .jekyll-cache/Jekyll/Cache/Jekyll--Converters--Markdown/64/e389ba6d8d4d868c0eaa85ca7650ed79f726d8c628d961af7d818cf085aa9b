I"<h2 id="참고">참고</h2>
<p>[망나니개발자님의 블로그][man]</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>본 내용은 망나니개발자님이 Coursera에서 Andrew ng 의 Machine Learning(기계학습, 머신러닝)을 수강한 내용을 정리한 것을 바탕으로 작성된 글입니다. 
</code></pre></div></div>

<p>이번 포스팅에서는 모델과 비용함수(Model and Cost Function)에 대해서 알아보겠습니다.</p>

<h2 id="1-gradient-descent경사하강법">1. Gradient Descent(경사하강법)</h2>

<h3 id="-gradient-descent-">[ Gradient Descent ]</h3>

<p>Gradient Descent Algorithm은 <strong>Cost Function $J(θ_0,θ_1)$ 을 최소로 만드는 $θ_0,θ_1$ 을 구하는 알고리즘</strong>으로 Linear Regression뿐만 아니라 머신러닝(기계학습)에서 전반적으로 사용되는 알고리즘입니다. Gradient Descent는 먼저 θ0,θ1 에 대한 임의의 초기값으로 시작합니다. 그리고 최소의 J(θ0,θ1) 을 찾을 때 까지 θ0,θ1 을 변경시킵니다. 즉, 이 알고리즘은 임의의 초기값을 기준으로 최소가 되는 점을 찾아나갑니다.</p>
:ET