I"*<h2 id="참고">참고</h2>
<p>[망나니개발자님의 블로그][man]</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>본 내용은 망나니개발자님이 Coursera에서 Andrew ng 의 Machine Learning(기계학습, 머신러닝)을 수강한 내용을 정리한 것을 바탕으로 작성된 글입니다. 
</code></pre></div></div>

<p>이번 포스팅에서는 모델과 비용함수(Model and Cost Function)에 대해서 알아보겠습니다.</p>

<h2 id="1-gradient-descent경사하강법">1. Gradient Descent(경사하강법)</h2>

<h3 id="-gradient-descent-">[ Gradient Descent ]</h3>

<p>Gradient Descent Algorithm은 <strong>Cost Function $J(θ_0,θ_1)$ 을 최소로 만드는 $θ_0,θ_1$ 을 구하는 알고리즘</strong>으로 Linear Regression뿐만 아니라 머신러닝(기계학습)에서 전반적으로 사용되는 알고리즘입니다.</p>

<p>Gradient Descent는 먼저 $θ_0,θ_1$ 에 대한 <em>임의의 초기값 $(x, y)$</em> 로 시작합니다. 그리고 최소의 $J(θ_0,θ_1)$ 을 찾을 때 까지 $θ_0,θ_1$ 을 변경시킵니다. 즉, 이 알고리즘은 임의의 초기값을 기준으로 최소가 되는 점을 찾아나갑니다.</p>

<p><img src="https://t1.daumcdn.net/cfile/tistory/99A123355A3A2DAF12" alt="그림1" /></p>

<p>Gradient Descent Algorithm을 수학적으로 정의하면 다음과 같습니다.</p>

<p>repeat until convergence{</p>

\[θ_j:=θ_j−α\frac{∂}{∂θ_j}J(θ_0,θ_1)\]

<p>}</p>

<ul>
  <li>$:=$ : Assignment Operator (대입 연산자)</li>
  <li>$α$ : Learning Rate (학습 속도)</li>
  <li>$\frac{∂}{∂θ_j}J(θ_0,θ_1)$ : Derivative Term (미분 계수)</li>
</ul>

<p>여기서 <strong>$:=$</strong> 는 <em>대입 연산자</em>로 <strong>$θ_j$ 에 $θ_j−α□$ 을 대입하겠다는 의미</strong>입니다.</p>

<p><strong>$α$</strong> 는 <em>Learning Rate</em>로 위의 그림에서처럼 <strong>언덕에서 내려갈 때 얼마나 큰 걸음으로 걸을 것인가를 나타내는 양의 상수</strong>이므로 $α$ 가 클수록 한 Step에 움직이는 길이가 길어집니다.</p>

<p><strong>$\frac{∂}{∂θ_j}J(θ_0,θ_1)$</strong> 는 <strong>비용함수를 $θ$에 대해 미분한 함수</strong>입니다. 미분해주는 값은 $J(θ_0,θ_1)$ 즉, 비용함수로 $θ_0,θ_1$ 총 2가지 변수에 의해 영향을 받고 있습니다.</p>

<p>우리는 이러한 대입의 과정을 지속해주어야 하는데, 아래의 오른쪽 그림<small>(글쓴이: 원본 글에서도 찾아볼 수 없습니다.)</small> 처럼 대입을 하면 $θ_1$의 값을 대입할 때 비용함수가 영향을 받으므로 왼쪽의 그림<small>(글쓴이: 마찬가지로 원본 글에서 찾아볼 수 없습니다.)</small> 처럼 <strong>Simultaneous 하게 동시에 Update를 해주어야 합니다.</strong></p>

<p>지금부터 경사 하강 알고리즘을 구성하는 요소들에서 Learning Rate $α$ 가 무엇을 하는지 그리고 왜 미분계수와 $α$ 를 곱한 $α\frac{∂}{∂θ_j}J(θ_0,θ_1)$를 이용하는지 이해를 돕기위해 하나의 Parameter $θ_1$ 만을 갖는 경우에 대해서 알아보도록 하겠습니다.</p>

<p><br /></p>

<h3 id="-derivative-term미분-계수-">[ Derivative Term(미분 계수) ]</h3>

<p>우리는 결국 $J(θ_1)$이 최소가 되는 실수 $θ_1$ 을 구해야 합니다.</p>

<p>아래와 같은 그림에서 파랑색의 $θ_1$ 을 초기값으로 최소값을 찾아나간다고 할 때, $\frac{∂}{∂θ_j}J(θ_1)$ 부분은 <strong>미분계수(한 점에서의 기울기 값)</strong> 즉, 초록색 직선의 기울기에 해당합니다. 또한 $α$ 가 양수이므로 $α\frac{∂}{∂θ_j}J(θ_1)$ 도 양수(Positive Number)가 되어 $θ$ 가 점점 줄어들며 최소로 가는 모습임을 알 수 있습니다. 그리고 이것이 바로 기울기 하강(Negative Slope)입니다.</p>

<p style="text-align:center;"><img src="https://t1.daumcdn.net/cfile/tistory/99C901415A3A564B1E" alt="그림2" width="400" /></p>

<p>$θ_1$ 이 좌측에 있는 경우에는 아래의 그림과 같이 미분계수가 음이 되고 $α$ 가 양수이므로 $α\frac{∂}{∂θ_j}J(θ_1)$ 이 음수(Negative Number)가 되어 전체는 양수가 되므로 $θ$ 가 점점 증가하며 최소로 가는 모습임을 알 수 있습니다. 그리고 이것이 바로 기울기 상승(Positive Slope)입니다</p>

<p style="text-align:center;"><img src="https://t1.daumcdn.net/cfile/tistory/9988033F5A3A57E21C" alt="그림3" width="400" /></p>

<p><br /></p>

<h3 id="-learning-rate학습-속도-">[ Learning Rate(학습 속도) ]</h3>

<p>그 다음으로 우리는 <strong>움직이는 보폭의 크기인 Learning Rate $α$</strong> 에 대해서 알아보아야 하는데, $α$ 의 값이 큰 경우와 작은 경우로 나누어 각각 어떤 문제를 발생시키는지 알아보겠습니다.</p>

<p>왼쪽의 그림과 같이 Learning Rate가 너무 작은 경우에는 최소값에 도달하기 위해 상당히 많은 연산을 필요로 하게됩니다. 그렇다고 Learning Rate가 너무 크면, (공식을 보고 예측을 해보면) 우리는 매우 큰 거리로 이동하므로 반대쪽 값으로 넘어가게 되며 최소값으로부터 점점 멀어지는 것을 확인할 수 있습니다.</p>

<p>그래서 우리는 Learning Rate를 적당한 값으로 설정해주어야 합니다.</p>

<p><img src="https://t1.daumcdn.net/cfile/tistory/99287D425A3A5E501F" alt="그림4" /></p>

<p><small>(글쓴이: 아래 내용은 개인적인 의견을 반영하여 원본 글과는 조금 다르게 작성하였습니다.)</small></p>

<p>마침내 우리는 왜 Learning Rate $α$ 와 Derivate Term $\frac{∂}{∂θ_j}J(θ_1)$ 을 함께 사용하는지에 대해 이해할 수 있습니다.</p>

<p>우리는 Dericate Term을 사용하여 최소값을 찾아갈 수 있고, 그 과정에서 적절한 Learning Rate를 설정해 줌으로써 조금 더 수월하게 진행할 수 있습니다.</p>

<p><br /></p>

<h3 id="-convergence수렴-">[ Convergence(수렴) ]</h3>

<p>그렇다면 Gradient descent이 수렴하여 연산을 종료하는 시간은 언제일까요?</p>

<p>그것은 바로 <strong>$\frac{∂}{∂θ_j}J(θ_1)$이 0이 되어 $θ_1$의 값이 더 이상 변하지 않을 경우</strong>입니다. 즉, $θ_1$ 이 이미 최적의 값(Local Optima)이여서 접선의 기울기가 0이고, Cost Function $J(θ_1)$이 최소가 되는 상황입니다.</p>

<p>그러나 언제나 깔끔하게 수렴하여 연산이 종료되지는 않습니다. 간혹 최소값으로 수렴하지 않고 제자리에서 진동하는 경우가 발생합니다.</p>

<p>이를 프로그램으로 구현한다면 연산이 종료되지 않는 문제가 발생하는데, 그것을 해결하기 위해선 <strong>충분히 만족스러운 결과의 척도나 연산 횟수를 설정하여 연산이 어느정도 진행되었을 때 종료</strong>시켜주는 것이 좋습니다.</p>

<p style="text-align:center;"><img src="https://t1.daumcdn.net/cfile/tistory/994D79365A3A65BC11" alt="그림5" width="500" /></p>

<hr />

<h2 id="2-gradient-descent-for-linear-regression">2. Gradient Descent for Linear Regression</h2>

<h3 id="-gradient-descent-for-linear-regression-">[ Gradient Descent for Linear Regression ]</h3>

<p>이제 우리는 아래의 그림과 같이 가설함수와 비용함수 그리고 최적의 비용함수를 갖는 $θ$를 찾기 위한 Gradient Descent 모두를 배웠습니다. 그러므로 이것들을 이용하여 우리의 데이터들에 맞는 직선(최적의 가설 함수)을 구해주기만 하면 됩니다.</p>

<p><img src="https://t1.daumcdn.net/cfile/tistory/99DDC0445A3A6A4418" alt="그림6" /></p>

<p>즉, Gradient Descent를 $J(θ_0,θ_1)$ 에 적용하여 Cost Function을 최소화시킬 것입니다. 그리고 이 과정에서 가장 중요한 것은 Gradient Descent Algorithm에서 $\frac{∂}{∂θ_j}J(θ_0,θ_1)$ 입니다. 원래의 예시에서는 $θ_0,θ_1$ 두개의 값을 가지므로 2개의 함수가 각각 나오게되고 미분을 직접 해보면 아래와 같이 나오게 됩니다.</p>

\[\frac{∂}{∂θ_j}J(θ_0,θ_1)~=~\frac{∂}{∂θ_j}[\frac{1}{2m}\sum_{i=1}^m(h_θ(x^i)−y^i)^2]\]

\[=~\frac{∂}{∂θ_j}[\frac{1}{2m}\sum_{i=1}^m(θ_0+θ_1x^i−y^i)^2]\]

<p>그리고 이것을 풀어서 계산하면 다음과 같습니다.</p>

\[j=0:\qquad\frac{∂}{∂θ_j}J(θ_0,θ_1)=m\sum_{i=1}^m(h_θ(x^i)−y^i)\]

\[j=1:\qquad\frac{∂}{∂θ_j}J(θ_0,θ_1)=m\sum_{i=1}^m(h_θ(x^i)−y^i)x^i\]

<p>그리고 이것을 Gradient descent algorithm에 적용하면 아래와 같습니다.</p>

<p style="text-align:center;"><img src="https://t1.daumcdn.net/cfile/tistory/9956CE3F5A3A6F4235" alt="그림7" width="400" /></p>

<p>앞에서 설명하였듯이 등고선이 복잡한 경우에는 아래의 그림과 같이 Global Optimal(실제 최소값) Local Optimal(특정 지역의 최소값)이 존재하여 초기값의 위치에 따라서 최적의 최소값이 달리집니다. 그러므로 초기값을 무엇으로 잡는지에 따라 우리가 얻게되는 $θ_0,θ_1$의 값이 달리집니다.</p>

<p style="text-align:center;"><img src="https://t1.daumcdn.net/cfile/tistory/99A0E3335A3A6FF42C" alt="그림8" width="350px" />
<img src="https://t1.daumcdn.net/cfile/tistory/99A1694D5A3A70FE1B" alt="그림9" width="350px" /></p>

<p>하지만 선형 회귀 Linear Regression의 Cost Function은 Convex Function(볼록 함수) 중에서도 위의 오른쪽 그림과 같은 Bowl-Shaped Function을 갖게 되고 Local Optima(지역적 최소값) 없이 Global Optima(전역적 최소값)만 갖게되므로 <strong>Linear Regression은 무조건 Global Optima로 수렴하게 되어있습니다.</strong> 그리고 이러한 규칙을 따라서 계속 Gradient Descent를 진행하면 빨간 점들을 지나서 최소값에 도달하게 됩니다</p>

<p><img src="https://t1.daumcdn.net/cfile/tistory/99DF4C4A5A3A716D30" alt="그림10" /></p>

<p><br /></p>

<h3 id="-batch-gradient-descent-">[ Batch Gradient Descent ]</h3>

<p>우리가 배운 Gradient Descent는 Batch Gradient Descent로 Batch의 뜻은 다음과 같습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   Batch: Each step of gradient descent uses all the training examples
</code></pre></div></div>

<p>즉, Gradient Descent 알고리즘을 사용하면서 <strong>매 단계마다 모든 Training Set를 활용한다</strong>는 말입니다. 실제로 우리는 Gradient Descent에서 미분계수를 계산할 때 $\sum^m_{i=1}$
을 사용하여 모든 Training Set에 대하여 계산을 해줍니다. 물론 모든 Data Set를 사용하지 않는 알고리즘도 존재합니다.</p>
:ET