I"Q"<h2 id="참고">참고</h2>
<p>[망나니개발자님의 블로그][man]</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>본 내용은 망나니개발자님이 Coursera에서 Andrew ng 의 Machine Learning(기계학습, 머신러닝)을 수강한 내용을 정리한 것을 바탕으로 작성된 글입니다. 
</code></pre></div></div>

<p>이번 포스팅에서는 모델과 비용함수(Model and Cost Function)에 대해서 알아보겠습니다.</p>

<h2 id="1-classification">1. Classification</h2>

<h3 id="-classification-">[ Classification ]</h3>
<p>우리가 앞에서 배운 Linear Regression이 주어진 Feature에 대해 Continuous(연속적인)한 Value를 Predict하는 방법이였다면, Classification은 <strong>주어진 Feature에 대해 Data들을 Discrete(이산적인)한 Class로 분류하는 방법</strong>으로 우리가 예측하기를 원하는 값 y는 분류된 클래스들 중 하나의 영역에 속하게 됩니다.</p>

<p>Classification문제의 예시로는 아래와 같은 것들이 있습니다.</p>

<ul>
  <li>
    <p>Email: Spam or Not Spam?</p>
  </li>
  <li>
    <p>Online Transactions: Fraudulent(Yes / No)?</p>
  </li>
  <li>
    <p>Tumor: Malignant / Benign?</p>
  </li>
</ul>

<p>예측값 y가 0이면 Negative Class 그리고 y가 1이면 Positive Class가 됩니다. 물론 Negative 와 Positive의 경계가 애매모호하기도 하고, 실제로는 분류되는 Class가 여러 개로 나누어지는 Multi-class Classification 문제인 경우가 많지만 우리는 0 or 1로 나누어지는 Binary Classification 문제를 먼저 다루어보도록 하겠습니다.</p>

<p><img src="https://t1.daumcdn.net/cfile/tistory/9961FC345A4CAA9F0A" alt="그림1" /></p>

<p><br /></p>

<h3 id="-classification-for-linear-regression-">[ Classification for Linear Regression ]</h3>

<p>예를 들어 아래의 그림과 같이 Tumor가 Malignant한지 아닌지를 판단하는 Classification 문제가 있다고 할 때, 아직 Classification 문제를 해결하는 방법을 배우지 못한 우리가 할 수 있는 것은 앞에서 배운 Linear Regression을 적용하여 Data에 맞는 직선을 구하는 것입니다.</p>

<p>아래의 왼쪽 그림과 같은 Training Set에서 $h_θ(x)=θ^Tx$ 를 구하면 파랑색의 직선이 나오고 우리는 예측값이 0.5보다 크면 Malignant라고 예측할 수 있습니다. 그리고 이것은 꽤나 잘 들어맞는 것처럼 보입니다.</p>

<ul>
  <li>
    <p>If $h_θ(x)≥0.5$, predict “$y=1$”</p>
  </li>
  <li>
    <p>If $h_θ(x)&lt;0.5$, predict “$y=0$”</p>
  </li>
</ul>

<p><img src="https://t1.daumcdn.net/cfile/tistory/99817D4A5A4CAD392C" alt="그림2" /></p>

<p>하지만 만약 오른쪽의 그림처럼 새로운 Example이 추가되었다고 할 때, y=0.5 의 기준점인 Tumor Size가 오른쪽으로 치우치면서 직선은 더 눕히게 되고 잘못된 예측을 하게 됩니다. 또한 Linear Regression을 적용하면 $h_θ(x)&gt;1$  or  $h_θ(x)&lt;0$ 인 경우도 발생합니다.</p>

<p>그래서 우리는 <strong>Classification을 위한 알고리즘으로 $0 \leq h_\theta(x) \leq 1$ 을 만족</strong>하는 Logistic Regression에 대해 배우도록 하겠습니다.</p>

<p><small>** 이름은 Logistic Regression이지만 Classfication을 위한 알고리즘이므로 헷갈리시면 안됩니다**</small></p>

<hr />

<h2 id="2-hypothesis-representation">2. Hypothesis Representation</h2>

<h3 id="-hypothesis-representation-">[ Hypothesis Representation ]</h3>
<p>이번에 알아볼 Hypothesis Representation은 우리의 가설을 표현하기 위한 함수입니다. $ 0 \leq h_\theta(x) \leq 1 $ 을 원하는 상황에서 우리가 위에서 세운 가설함수 $h_θ(x)=θ^Tx$ 는 범위를 만족하지 않으며 잘못된 예측을 할 수 있어서 적합하지 않습니다.</p>

<p>때문에 Logistic Regression 에서는 $h_θ(x)=g(θ^Tx)$ 로 가설함수를 표현합니다. 그리고 여기서 $g(z)=\frac{1}{1+e^{−z}}$ 이므로 이를 정리하여 나타내면 아래와 같습니다.</p>

\[h_\theta(x) = \frac{1}{1 + e^{-\theta^Tx}}\]

<p>이 그래프는 0과 1로 수렴하며 그래프의 개형은 아래와 같습니다.</p>

<p style="text-align:center;"><img src="https://t1.daumcdn.net/cfile/tistory/99F89C335A4CE10F1A" width="500" alt="그림3" /></p>

<p>덧붙여서 여기에 자연상수 e 대신 다른 수를 집어 넣으면 형태는 비슷하나 기울기가 다른 곡선이 만들어집니다.</p>

<video controls="">
    <source src="/assets/imgs/post_30/example.mp4" type="video/mp4" />
    Your browser does not support the video tag.
</video>

<p>이제 우리가 해야 할 것은 파라미터 $θ$ 들을 데이터에 맞추는 것입니다. 우리는 주어진 Training Example로부터 $θ$를 정하고 이 가설함수를 통해 예측을 할 수 있습니다.</p>

<p>하지만 $θ$ 를 구하는 알고리즘을 배우기 전에 $h_θ(x)$ 에 대해 해석해보도록 하겠습니다.</p>

<p><br /></p>

<h3 id="-interpretation-of-hypothesis-output-">[ Interpretation of Hypothesis Output ]</h3>

\[h_θ(x)=P(y=1|x;θ)\]

<p>h의 출력값은 Feature X를 가지고 있는 경우에 $y=1$인 Class에 들어갈 확률을 의미합니다. 예를 들어 입력벡터 x가 아래와 같다고 할 때 $h_θ(x) = 0.7$ 이라는 것은 Tumor가 Malignant일 확률이 70%라는 것을 의미합니다.</p>

<p>또한 결국에 입력 x의 결과는 Class1 또는 Class0에 속해야 하므로 $y=1$ (Class1)일 확률과 $y=2$ (Class2)일 확률의 합은 1이 되어야 합니다.</p>

\[P(y=0|x;θ)+P(y=1|x;θ)=1\]

<p style="text-align:center;"><img src="https://t1.daumcdn.net/cfile/tistory/9902773F5A4D7AFF14" alt="그림4" /></p>

<hr />

<h2 id="3-decision-boundary">3. Decision Boundary</h2>

<h3 id="-logistic-regression-">[ Logistic Regression ]</h3>
<p>이번에 우리가 공부할 내용은 언제 이 가설이 $y=1$임을 예측하고 언제 $y=0$임을 예측하는가(어떠한 경계를 기준으로) 그리고 1개 이상의 Feature를 가질 때 어떤 모습을 보이는가 입니다.</p>

<p>앞서서 우리는 $h_θ(x)=g(θ^Tx)$ 이며 $g(z)=\frac{1}{1+e^{−z}}$ 임을 배웠고, 아래와 같이 판단한다고 이야기했습니다.</p>

<ul>
  <li>
    <p>If $h_θ(x)≥0.5$, predict “$y=1$”</p>
  </li>
  <li>
    <p>If $h_θ(x)&lt;0.5$, predict “$y=0$”</p>
  </li>
</ul>

<p>위의 그래프의 개형은 아래와 같으며 $h_θ(x)≥0.5$ 인 부분은 $z≥0$ 인 영역과 같습니다.  그렇다면 $y=0$인 Class0에 속하는 경우는 언제일까요? 바로 $z&lt;0$ 인 영역이며 $z=0$을 기준으로 Class가 나뉘어지고 있으므로 Decision Boundary는 $z=0$이 됩니다.</p>

<p style="text-align:center;"><img src="https://t1.daumcdn.net/cfile/tistory/99F89C335A4CE10F1A" width="500" alt="그림3" /></p>

<p><br /></p>

<h3 id="-decision-boundary-">[ Decision Boundary ]</h3>

<p>$x1$,$x2$ 를 Feature로 갖는 Training Set이 아래와 같이 주어졌다고 하고, 가설함수는 $h_θ(x)=g(θ_0+θ_1x_1+θ_2x_2)$ 라고 할 때, 아직 $θ$ 를 구하는 방법은 배우지 못했으므로 각각의 $θ$ 를 $-3$, $1$, $1$ 이라고 가정하겠습니다. 이때 $h$는 언제 $y=1$ 또는 $y=0$으로 예측을 할까요?</p>

<p style="text-align:center;"><img src="https://t1.daumcdn.net/cfile/tistory/990D78385A4D863603" width="500" alt="그림5" /></p>

<p>우리는 위에서 배운 내용들로 $θ^Tx=z$ 에 해당하는 $−3+x_1+x_2≥0$ 이라면 $y=1$로 예측할 것임을 알 수 있고, 이 영역은 위의 초록색 영역으로 나뉘어진 영역들 중 1시 방향의 영역을 의미합니다.</p>

<p>반대로 $z=−3+x_1+x_2&lt;0$인 부분은 7시 방향의 영역으로 $y=0$인 Class에 속하게 되고, 여기서 생긴 경계(직선)이 Decision Boundary가 됩니다.</p>

<p>정리하자면 <strong>Decision Boundary는 Class들을 나누는 경계</strong>를 의미합니다. 그리고 이러한 Decision Boudary는 Training Set이 아니라 Property로 $θ$ 벡터에 의해 결정이 됩니다.</p>

<h3 id="-non-linear-decision-boundaries-">[ Non-Linear Decision Boundaries ]</h3>

<p>이번에는 보다 복잡한 에시의 Decision Boundary에 대해 알아보도록 하겠습니다. 예를 들어 아래의 그림과 같은 Data Set이 주어졌다고 할 때, 직선으로 Class를 구분하는 것은 불가능해보입니다. 그래서 가설함수를 hθ(x)=g(θ0+θ1x1+θ2x2+θ3x21+θ4x22
와 같이 세웠다고 할 때, 5개의 Parameter들이 순차적으로 -1, 0, 0, 1, 1 을 갖게 된다고 합시다. 그렇다면 우리는 아래와 같이 예측을 할 수 있습니다.</p>
:ET